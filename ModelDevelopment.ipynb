{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from docker container 002\n",
      "hello from docker container on macbook 001\n",
      "hello from fury 001\n",
      "hello from a swarm containers 001\n",
      "hello from tensorflow-gpu container\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"hello from docker container 002\")\n",
    "print(\"hello from docker container on macbook 001\")\n",
    "print(\"hello from fury 001\")\n",
    "print(\"hello from a swarm containers 001\")\n",
    "print(\"hello from tensorflow-gpu container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  /home/jovyan/work/Python\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory \" , os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>158.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>105.8</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>17710.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling  normalized-losses  make fuel-type aspiration num-of-doors  \\\n",
       "0          2              164.0  audi       gas        std         four   \n",
       "1          2              164.0  audi       gas        std         four   \n",
       "2          1              158.0  audi       gas        std         four   \n",
       "\n",
       "  body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n",
       "0      sedan          fwd           front        99.8  ...          109   \n",
       "1      sedan          4wd           front        99.4  ...          136   \n",
       "2      sedan          fwd           front       105.8  ...          136   \n",
       "\n",
       "   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n",
       "0         mpfi  3.19     3.4              10.0      102.0    5500.0       24   \n",
       "1         mpfi  3.19     3.4               8.0      115.0    5500.0       18   \n",
       "2         mpfi  3.19     3.4               8.5      110.0    5500.0       19   \n",
       "\n",
       "   highway-mpg    price  \n",
       "0           30  13950.0  \n",
       "1           22  17450.0  \n",
       "2           25  17710.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data/cars_data_df2.csv\")\n",
    "df3.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a LinearRegression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   highway-mpg\n",
      "0           30\n",
      "1           22\n",
      "2           25\n",
      "3           20\n",
      "lm.intercept_ =  32398.971731070436\n",
      "lm.intercept_ =  [-653.94786142]\n"
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "X = df3[[\"highway-mpg\"]]\n",
    "Y = df3[\"price\"]\n",
    "\n",
    "# list some values of X\n",
    "print(X.head(4))\n",
    "\n",
    "lm.fit(X, Y)\n",
    "\n",
    "print(\"lm.intercept_ = \",lm.intercept_)\n",
    "print(\"lm.intercept_ = \",lm.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17946.72399358, 17881.32920744])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {\"highway-mpg\":pd.Series([22.1,22.2])}\n",
    "x = pd.DataFrame(x)\n",
    "\n",
    "y_hat = lm.predict(x)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlowess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mx_partial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_partial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrobust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscatter_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mline_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Plot the residuals of a linear regression.\n",
       "\n",
       "This function will regress y on x (possibly as a robust or polynomial\n",
       "regression) and then draw a scatterplot of the residuals. You can\n",
       "optionally fit a lowess smoother to the residual plot, which can\n",
       "help in determining if there is structure to the residuals.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : vector or string\n",
       "    Data or column name in `data` for the predictor variable.\n",
       "y : vector or string\n",
       "    Data or column name in `data` for the response variable.\n",
       "data : DataFrame, optional\n",
       "    DataFrame to use if `x` and `y` are column names.\n",
       "lowess : boolean, optional\n",
       "    Fit a lowess smoother to the residual scatterplot.\n",
       "{x, y}_partial : matrix or string(s) , optional\n",
       "    Matrix with same first dimension as `x`, or column name(s) in `data`.\n",
       "    These variables are treated as confounding and are removed from\n",
       "    the `x` or `y` variables before plotting.\n",
       "order : int, optional\n",
       "    Order of the polynomial to fit when calculating the residuals.\n",
       "robust : boolean, optional\n",
       "    Fit a robust linear regression when calculating the residuals.\n",
       "dropna : boolean, optional\n",
       "    If True, ignore observations with missing data when fitting and\n",
       "    plotting.\n",
       "label : string, optional\n",
       "    Label that will be used in any plot legends.\n",
       "color : matplotlib color, optional\n",
       "    Color to use for all elements of the plot.\n",
       "{scatter, line}_kws : dictionaries, optional\n",
       "    Additional keyword arguments passed to scatter() and plot() for drawing\n",
       "    the components of the plot.\n",
       "ax : matplotlib axis, optional\n",
       "    Plot into this axis, otherwise grab the current axis or make a new\n",
       "    one if not existing.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "ax: matplotlib axes\n",
       "    Axes with the regression plot.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "regplot : Plot a simple linear regression model.\n",
       "jointplot (with kind=\"resid\"): Draw a residplot with univariate\n",
       "                               marginal distrbutions.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/seaborn/regression.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using seaborn residplot\n",
    "sns.residplot(df3[\"highway-mpg\"], df3[\"price\"], lowess = True)\n",
    "?sns.residplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhist_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkde_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrug_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvertical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnorm_hist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Flexibly plot a univariate distribution of observations.\n",
       "\n",
       "This function combines the matplotlib ``hist`` function (with automatic\n",
       "calculation of a good default bin size) with the seaborn :func:`kdeplot`\n",
       "and :func:`rugplot` functions. It can also fit ``scipy.stats``\n",
       "distributions and plot the estimated PDF over the data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "\n",
       "a : Series, 1d-array, or list.\n",
       "    Observed data. If this is a Series object with a ``name`` attribute,\n",
       "    the name will be used to label the data axis.\n",
       "bins : argument for matplotlib hist(), or None, optional\n",
       "    Specification of hist bins, or None to use Freedman-Diaconis rule.\n",
       "hist : bool, optional\n",
       "    Whether to plot a (normed) histogram.\n",
       "kde : bool, optional\n",
       "    Whether to plot a gaussian kernel density estimate.\n",
       "rug : bool, optional\n",
       "    Whether to draw a rugplot on the support axis.\n",
       "fit : random variable object, optional\n",
       "    An object with `fit` method, returning a tuple that can be passed to a\n",
       "    `pdf` method a positional arguments following an grid of values to\n",
       "    evaluate the pdf on.\n",
       "{hist, kde, rug, fit}_kws : dictionaries, optional\n",
       "    Keyword arguments for underlying plotting functions.\n",
       "color : matplotlib color, optional\n",
       "    Color to plot everything but the fitted curve in.\n",
       "vertical : bool, optional\n",
       "    If True, observed values are on y-axis.\n",
       "norm_hist : bool, optional\n",
       "    If True, the histogram height shows a density rather than a count.\n",
       "    This is implied if a KDE or fitted density is plotted.\n",
       "axlabel : string, False, or None, optional\n",
       "    Name for the support axis label. If None, will try to get it\n",
       "    from a.namel if False, do not set a label.\n",
       "label : string, optional\n",
       "    Legend label for the relevent component of the plot\n",
       "ax : matplotlib axis, optional\n",
       "    if provided, plot on this axis\n",
       "\n",
       "Returns\n",
       "-------\n",
       "ax : matplotlib Axes\n",
       "    Returns the Axes object with the plot for further tweaking.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "kdeplot : Show a univariate or bivariate distribution with a kernel\n",
       "          density estimate.\n",
       "rugplot : Draw small vertical lines to show each observation in a\n",
       "          distribution.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "Show a default plot with a kernel density estimate and histogram with bin\n",
       "size determined automatically with a reference rule:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> import seaborn as sns, numpy as np\n",
       "    >>> sns.set(); np.random.seed(0)\n",
       "    >>> x = np.random.randn(100)\n",
       "    >>> ax = sns.distplot(x)\n",
       "\n",
       "Use Pandas objects to get an informative axis label:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> import pandas as pd\n",
       "    >>> x = pd.Series(x, name=\"x variable\")\n",
       "    >>> ax = sns.distplot(x)\n",
       "\n",
       "Plot the distribution with a kernel density estimate and rug plot:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.distplot(x, rug=True, hist=False)\n",
       "\n",
       "Plot the distribution with a histogram and maximum likelihood gaussian\n",
       "distribution fit:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> from scipy.stats import norm\n",
       "    >>> ax = sns.distplot(x, fit=norm, kde=False)\n",
       "\n",
       "Plot the distribution on the vertical axis:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.distplot(x, vertical=True)\n",
       "\n",
       "Change the color of all the plot elements:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> sns.set_color_codes()\n",
       "    >>> ax = sns.distplot(x, color=\"y\")\n",
       "\n",
       "Pass specific parameters to the underlying plot functions:\n",
       "\n",
       ".. plot::\n",
       "    :context: close-figs\n",
       "\n",
       "    >>> ax = sns.distplot(x, rug=True, rug_kws={\"color\": \"g\"},\n",
       "    ...                   kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},\n",
       "    ...                   hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n",
       "    ...                             \"alpha\": 1, \"color\": \"g\"})\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/seaborn/distributions.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_1 = sns.distplot(df3[\"price\"], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(y_hat, hist=False, color=\"b\", label = \"Fitted Values\", ax=ax_1)\n",
    "\n",
    "?sns.distplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polinomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Least squares polynomial fit.\n",
       "\n",
       "Fit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`\n",
       "to points `(x, y)`. Returns a vector of coefficients `p` that minimises\n",
       "the squared error.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : array_like, shape (M,)\n",
       "    x-coordinates of the M sample points ``(x[i], y[i])``.\n",
       "y : array_like, shape (M,) or (M, K)\n",
       "    y-coordinates of the sample points. Several data sets of sample\n",
       "    points sharing the same x-coordinates can be fitted at once by\n",
       "    passing in a 2D-array that contains one dataset per column.\n",
       "deg : int\n",
       "    Degree of the fitting polynomial\n",
       "rcond : float, optional\n",
       "    Relative condition number of the fit. Singular values smaller than\n",
       "    this relative to the largest singular value will be ignored. The\n",
       "    default value is len(x)*eps, where eps is the relative precision of\n",
       "    the float type, about 2e-16 in most cases.\n",
       "full : bool, optional\n",
       "    Switch determining nature of return value. When it is False (the\n",
       "    default) just the coefficients are returned, when True diagnostic\n",
       "    information from the singular value decomposition is also returned.\n",
       "w : array_like, shape (M,), optional\n",
       "    Weights to apply to the y-coordinates of the sample points. For\n",
       "    gaussian uncertainties, use 1/sigma (not 1/sigma**2).\n",
       "cov : bool, optional\n",
       "    Return the estimate and the covariance matrix of the estimate\n",
       "    If full is True, then cov is not returned.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "p : ndarray, shape (deg + 1,) or (deg + 1, K)\n",
       "    Polynomial coefficients, highest power first.  If `y` was 2-D, the\n",
       "    coefficients for `k`-th data set are in ``p[:,k]``.\n",
       "\n",
       "residuals, rank, singular_values, rcond\n",
       "    Present only if `full` = True.  Residuals of the least-squares fit,\n",
       "    the effective rank of the scaled Vandermonde coefficient matrix,\n",
       "    its singular values, and the specified value of `rcond`. For more\n",
       "    details, see `linalg.lstsq`.\n",
       "\n",
       "V : ndarray, shape (M,M) or (M,M,K)\n",
       "    Present only if `full` = False and `cov`=True.  The covariance\n",
       "    matrix of the polynomial coefficient estimates.  The diagonal of\n",
       "    this matrix are the variance estimates for each coefficient.  If y\n",
       "    is a 2-D array, then the covariance matrix for the `k`-th data set\n",
       "    are in ``V[:,:,k]``\n",
       "\n",
       "\n",
       "Warns\n",
       "-----\n",
       "RankWarning\n",
       "    The rank of the coefficient matrix in the least-squares fit is\n",
       "    deficient. The warning is only raised if `full` = False.\n",
       "\n",
       "    The warnings can be turned off by\n",
       "\n",
       "    >>> import warnings\n",
       "    >>> warnings.simplefilter('ignore', np.RankWarning)\n",
       "\n",
       "See Also\n",
       "--------\n",
       "polyval : Compute polynomial values.\n",
       "linalg.lstsq : Computes a least-squares fit.\n",
       "scipy.interpolate.UnivariateSpline : Computes spline fits.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The solution minimizes the squared error\n",
       "\n",
       ".. math ::\n",
       "    E = \\sum_{j=0}^k |p(x_j) - y_j|^2\n",
       "\n",
       "in the equations::\n",
       "\n",
       "    x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n",
       "    x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]\n",
       "    ...\n",
       "    x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]\n",
       "\n",
       "The coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n",
       "\n",
       "`polyfit` issues a `RankWarning` when the least-squares fit is badly\n",
       "conditioned. This implies that the best fit is not well-defined due\n",
       "to numerical error. The results may be improved by lowering the polynomial\n",
       "degree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter\n",
       "can also be set to a value smaller than its default, but the resulting\n",
       "fit may be spurious: including contributions from the small singular\n",
       "values can add numerical noise to the result.\n",
       "\n",
       "Note that fitting polynomial coefficients is inherently badly conditioned\n",
       "when the degree of the polynomial is large or the interval of sample points\n",
       "is badly centered. The quality of the fit should always be checked in these\n",
       "cases. When polynomial fits are not satisfactory, splines may be a good\n",
       "alternative.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] Wikipedia, \"Curve fitting\",\n",
       "       http://en.wikipedia.org/wiki/Curve_fitting\n",
       ".. [2] Wikipedia, \"Polynomial interpolation\",\n",
       "       http://en.wikipedia.org/wiki/Polynomial_interpolation\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
       ">>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
       ">>> z = np.polyfit(x, y, 3)\n",
       ">>> z\n",
       "array([ 0.08703704, -0.81349206,  1.69312169, -0.03968254])\n",
       "\n",
       "It is convenient to use `poly1d` objects for dealing with polynomials:\n",
       "\n",
       ">>> p = np.poly1d(z)\n",
       ">>> p(0.5)\n",
       "0.6143849206349179\n",
       ">>> p(3.5)\n",
       "-0.34732142857143039\n",
       ">>> p(10)\n",
       "22.579365079365115\n",
       "\n",
       "High-order polynomials may oscillate wildly:\n",
       "\n",
       ">>> p30 = np.poly1d(np.polyfit(x, y, 30))\n",
       "/... RankWarning: Polyfit may be poorly conditioned...\n",
       ">>> p30(4)\n",
       "-0.80000000000000204\n",
       ">>> p30(5)\n",
       "-0.99999999999999445\n",
       ">>> p30(4.5)\n",
       "-0.10547061179440398\n",
       "\n",
       "Illustration:\n",
       "\n",
       ">>> import matplotlib.pyplot as plt\n",
       ">>> xp = np.linspace(-2, 6, 100)\n",
       ">>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n",
       ">>> plt.ylim(-2,2)\n",
       "(-2, 2)\n",
       ">>> plt.show()\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/numpy/lib/polynomial.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08703704 -0.81349206  1.69312169 -0.03968254]\n",
      "         3          2\n",
      "0.08704 x - 0.8135 x + 1.693 x - 0.03968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoly1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_or_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A one-dimensional polynomial class.\n",
       "\n",
       "A convenience class, used to encapsulate \"natural\" operations on\n",
       "polynomials so that said operations may take on their customary\n",
       "form in code (see Examples).\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "c_or_r : array_like\n",
       "    The polynomial's coefficients, in decreasing powers, or if\n",
       "    the value of the second parameter is True, the polynomial's\n",
       "    roots (values where the polynomial evaluates to 0).  For example,\n",
       "    ``poly1d([1, 2, 3])`` returns an object that represents\n",
       "    :math:`x^2 + 2x + 3`, whereas ``poly1d([1, 2, 3], True)`` returns\n",
       "    one that represents :math:`(x-1)(x-2)(x-3) = x^3 - 6x^2 + 11x -6`.\n",
       "r : bool, optional\n",
       "    If True, `c_or_r` specifies the polynomial's roots; the default\n",
       "    is False.\n",
       "variable : str, optional\n",
       "    Changes the variable used when printing `p` from `x` to `variable`\n",
       "    (see Examples).\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Construct the polynomial :math:`x^2 + 2x + 3`:\n",
       "\n",
       ">>> p = np.poly1d([1, 2, 3])\n",
       ">>> print(np.poly1d(p))\n",
       "   2\n",
       "1 x + 2 x + 3\n",
       "\n",
       "Evaluate the polynomial at :math:`x = 0.5`:\n",
       "\n",
       ">>> p(0.5)\n",
       "4.25\n",
       "\n",
       "Find the roots:\n",
       "\n",
       ">>> p.r\n",
       "array([-1.+1.41421356j, -1.-1.41421356j])\n",
       ">>> p(p.r)\n",
       "array([ -4.44089210e-16+0.j,  -4.44089210e-16+0.j])\n",
       "\n",
       "These numbers in the previous line represent (0, 0) to machine precision\n",
       "\n",
       "Show the coefficients:\n",
       "\n",
       ">>> p.c\n",
       "array([1, 2, 3])\n",
       "\n",
       "Display the order (the leading zero-coefficients are removed):\n",
       "\n",
       ">>> p.order\n",
       "2\n",
       "\n",
       "Show the coefficient of the k-th power in the polynomial\n",
       "(which is equivalent to ``p.c[-(i+1)]``):\n",
       "\n",
       ">>> p[1]\n",
       "2\n",
       "\n",
       "Polynomials can be added, subtracted, multiplied, and divided\n",
       "(returns quotient and remainder):\n",
       "\n",
       ">>> p * p\n",
       "poly1d([ 1,  4, 10, 12,  9])\n",
       "\n",
       ">>> (p**3 + 4) / p\n",
       "(poly1d([  1.,   4.,  10.,  12.,   9.]), poly1d([ 4.]))\n",
       "\n",
       "``asarray(p)`` gives the coefficient array, so polynomials can be\n",
       "used in all functions that accept arrays:\n",
       "\n",
       ">>> p**2 # square of polynomial\n",
       "poly1d([ 1,  4, 10, 12,  9])\n",
       "\n",
       ">>> np.square(p) # square of individual coefficients\n",
       "array([1, 4, 9])\n",
       "\n",
       "The variable used in the string representation of `p` can be modified,\n",
       "using the `variable` parameter:\n",
       "\n",
       ">>> p = np.poly1d([1,2,3], variable='z')\n",
       ">>> print(p)\n",
       "   2\n",
       "1 z + 2 z + 3\n",
       "\n",
       "Construct a polynomial from its roots:\n",
       "\n",
       ">>> np.poly1d([1, 2], True)\n",
       "poly1d([ 1, -3,  2])\n",
       "\n",
       "This is the same polynomial as obtained by:\n",
       "\n",
       ">>> np.poly1d([1, -1]) * np.poly1d([1, -2])\n",
       "poly1d([ 1, -3,  2])\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/numpy/lib/polynomial.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     orthopoly1d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
    "y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
    "\n",
    "# fit a polynomial regreession model of 3rd degree\n",
    "z = np.polyfit(x, y, 3)\n",
    "print(z)\n",
    "\n",
    "p = np.poly1d(z)\n",
    "print(p)\n",
    "?np.poly1d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: RankWarning: Polyfit may be poorly conditioned\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = np.poly1d(z)\n",
    "p30 = np.poly1d(np.polyfit(x, y, 30))\n",
    "xp = np.linspace(-2, 6, 100)\n",
    "plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polinomial regression with more than one dimension\n",
    "this is not supported by numpy\n",
    "wee need to import *sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Generate polynomial and interaction features.\n",
       "\n",
       "Generate a new feature matrix consisting of all polynomial combinations\n",
       "of the features with degree less than or equal to the specified degree.\n",
       "For example, if an input sample is two dimensional and of the form\n",
       "[a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "degree : integer\n",
       "    The degree of the polynomial features. Default = 2.\n",
       "\n",
       "interaction_only : boolean, default = False\n",
       "    If true, only interaction features are produced: features that are\n",
       "    products of at most ``degree`` *distinct* input features (so not\n",
       "    ``x[1] ** 2``, ``x[0] * x[2] ** 3``, etc.).\n",
       "\n",
       "include_bias : boolean\n",
       "    If True (default), then include a bias column, the feature in which\n",
       "    all polynomial powers are zero (i.e. a column of ones - acts as an\n",
       "    intercept term in a linear model).\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> X = np.arange(6).reshape(3, 2)\n",
       ">>> X\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])\n",
       ">>> poly = PolynomialFeatures(2)\n",
       ">>> poly.fit_transform(X)\n",
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])\n",
       ">>> poly = PolynomialFeatures(interaction_only=True)\n",
       ">>> poly.fit_transform(X)\n",
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "powers_ : array, shape (n_output_features, n_input_features)\n",
       "    powers_[i, j] is the exponent of the jth input in the ith output.\n",
       "\n",
       "n_input_features_ : int\n",
       "    The total number of input features.\n",
       "\n",
       "n_output_features_ : int\n",
       "    The total number of polynomial output features. The number of output\n",
       "    features is computed by iterating over all suitably sized combinations\n",
       "    of input features.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Be aware that the number of features in the output array scales\n",
       "polynomially in the number of features of the input array, and\n",
       "exponentially in the degree. High degrees can cause overfitting.\n",
       "\n",
       "See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
       "<sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conda install scikit-learn\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "?PolynomialFeatures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[[  1.   0.   1.   0.   0.   1.   0.   0.   0.   1.]\n",
      " [  1.   2.   3.   4.   6.   9.   8.  12.  18.  27.]\n",
      " [  1.   4.   5.  16.  20.  25.  64.  80. 100. 125.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(6).reshape(3,2)\n",
    "print(X)\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "print(poly.fit_transform(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Standardize features by removing the mean and scaling to unit variance\n",
       "\n",
       "The standard score of a sample `x` is calculated as:\n",
       "\n",
       "    z = (x - u) / s\n",
       "\n",
       "where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
       "and `s` is the standard deviation of the training samples or one if\n",
       "`with_std=False`.\n",
       "\n",
       "Centering and scaling happen independently on each feature by computing\n",
       "the relevant statistics on the samples in the training set. Mean and\n",
       "standard deviation are then stored to be used on later data using the\n",
       "`transform` method.\n",
       "\n",
       "Standardization of a dataset is a common requirement for many\n",
       "machine learning estimators: they might behave badly if the\n",
       "individual features do not more or less look like standard normally\n",
       "distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
       "\n",
       "For instance many elements used in the objective function of\n",
       "a learning algorithm (such as the RBF kernel of Support Vector\n",
       "Machines or the L1 and L2 regularizers of linear models) assume that\n",
       "all features are centered around 0 and have variance in the same\n",
       "order. If a feature has a variance that is orders of magnitude larger\n",
       "that others, it might dominate the objective function and make the\n",
       "estimator unable to learn from other features correctly as expected.\n",
       "\n",
       "This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
       "`with_mean=False` to avoid breaking the sparsity structure of the data.\n",
       "\n",
       "Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "copy : boolean, optional, default True\n",
       "    If False, try to avoid a copy and do inplace scaling instead.\n",
       "    This is not guaranteed to always work inplace; e.g. if the data is\n",
       "    not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
       "    returned.\n",
       "\n",
       "with_mean : boolean, True by default\n",
       "    If True, center the data before scaling.\n",
       "    This does not work (and will raise an exception) when attempted on\n",
       "    sparse matrices, because centering them entails building a dense\n",
       "    matrix which in common use cases is likely to be too large to fit in\n",
       "    memory.\n",
       "\n",
       "with_std : boolean, True by default\n",
       "    If True, scale the data to unit variance (or equivalently,\n",
       "    unit standard deviation).\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "scale_ : ndarray or None, shape (n_features,)\n",
       "    Per feature relative scaling of the data. This is calculated using\n",
       "    `np.sqrt(var_)`. Equal to ``None`` when ``with_std=False``.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *scale_*\n",
       "\n",
       "mean_ : ndarray or None, shape (n_features,)\n",
       "    The mean value for each feature in the training set.\n",
       "    Equal to ``None`` when ``with_mean=False``.\n",
       "\n",
       "var_ : ndarray or None, shape (n_features,)\n",
       "    The variance for each feature in the training set. Used to compute\n",
       "    `scale_`. Equal to ``None`` when ``with_std=False``.\n",
       "\n",
       "n_samples_seen_ : int or array, shape (n_features,)\n",
       "    The number of samples processed by the estimator for each feature.\n",
       "    If there are not missing samples, the ``n_samples_seen`` will be an\n",
       "    integer, otherwise it will be an array.\n",
       "    Will be reset on new calls to fit, but increments across\n",
       "    ``partial_fit`` calls.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.preprocessing import StandardScaler\n",
       ">>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
       ">>> scaler = StandardScaler()\n",
       ">>> print(scaler.fit(data))\n",
       "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
       ">>> print(scaler.mean_)\n",
       "[0.5 0.5]\n",
       ">>> print(scaler.transform(data))\n",
       "[[-1. -1.]\n",
       " [-1. -1.]\n",
       " [ 1.  1.]\n",
       " [ 1.  1.]]\n",
       ">>> print(scaler.transform([[2, 2]]))\n",
       "[[3. 3.]]\n",
       "\n",
       "See also\n",
       "--------\n",
       "scale: Equivalent function without the estimator API.\n",
       "\n",
       ":class:`sklearn.decomposition.PCA`\n",
       "    Further removes the linear correlation across features with 'whiten=True'.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "NaNs are treated as missing values: disregarded in fit, and maintained in\n",
       "transform.\n",
       "\n",
       "We use a biased estimator for the standard deviation, equivalent to\n",
       "`numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
       "affect model performance.\n",
       "\n",
       "For a comparison of the different scalers, transformers, and normalizers,\n",
       "see :ref:`examples/preprocessing/plot_all_scaling.py\n",
       "<sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 0], [1, 0], [1, 1], [1, 1]]\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[4.  0.5]\n",
      "[[ 1.73205081 -1.        ]\n",
      " [-0.57735027 -1.        ]\n",
      " [-0.57735027  1.        ]\n",
      " [-0.57735027  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "data = [[13, 0], [1, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "print(data)\n",
    "print(scaler.fit(data))\n",
    "print(scaler.mean_)\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.76980036 -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.transform([[0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Pipeline of transforms with a final estimator.\n",
       "\n",
       "Sequentially apply a list of transforms and a final estimator.\n",
       "Intermediate steps of the pipeline must be 'transforms', that is, they\n",
       "must implement fit and transform methods.\n",
       "The final estimator only needs to implement fit.\n",
       "The transformers in the pipeline can be cached using ``memory`` argument.\n",
       "\n",
       "The purpose of the pipeline is to assemble several steps that can be\n",
       "cross-validated together while setting different parameters.\n",
       "For this, it enables setting parameters of the various steps using their\n",
       "names and the parameter name separated by a '__', as in the example below.\n",
       "A step's estimator may be replaced entirely by setting the parameter\n",
       "with its name to another estimator, or a transformer removed by setting\n",
       "to None.\n",
       "\n",
       "Read more in the :ref:`User Guide <pipeline>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "steps : list\n",
       "    List of (name, transform) tuples (implementing fit/transform) that are\n",
       "    chained, in the order in which they are chained, with the last object\n",
       "    an estimator.\n",
       "\n",
       "memory : None, str or object with the joblib.Memory interface, optional\n",
       "    Used to cache the fitted transformers of the pipeline. By default,\n",
       "    no caching is performed. If a string is given, it is the path to\n",
       "    the caching directory. Enabling caching triggers a clone of\n",
       "    the transformers before fitting. Therefore, the transformer\n",
       "    instance given to the pipeline cannot be inspected\n",
       "    directly. Use the attribute ``named_steps`` or ``steps`` to\n",
       "    inspect estimators within the pipeline. Caching the\n",
       "    transformers is advantageous when fitting is time consuming.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "named_steps : bunch object, a dictionary with attribute access\n",
       "    Read-only attribute to access any step parameter by user given name.\n",
       "    Keys are step names and values are steps parameters.\n",
       "\n",
       "See also\n",
       "--------\n",
       "sklearn.pipeline.make_pipeline : convenience function for simplified\n",
       "    pipeline construction.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn import svm\n",
       ">>> from sklearn.datasets import samples_generator\n",
       ">>> from sklearn.feature_selection import SelectKBest\n",
       ">>> from sklearn.feature_selection import f_regression\n",
       ">>> from sklearn.pipeline import Pipeline\n",
       ">>> # generate some data to play with\n",
       ">>> X, y = samples_generator.make_classification(\n",
       "...     n_informative=5, n_redundant=0, random_state=42)\n",
       ">>> # ANOVA SVM-C\n",
       ">>> anova_filter = SelectKBest(f_regression, k=5)\n",
       ">>> clf = svm.SVC(kernel='linear')\n",
       ">>> anova_svm = Pipeline([('anova', anova_filter), ('svc', clf)])\n",
       ">>> # You can set the parameters using the names issued\n",
       ">>> # For instance, fit using a k of 10 in the SelectKBest\n",
       ">>> # and a parameter 'C' of the svm\n",
       ">>> anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)\n",
       "...                      # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n",
       "Pipeline(memory=None,\n",
       "         steps=[('anova', SelectKBest(...)),\n",
       "                ('svc', SVC(...))])\n",
       ">>> prediction = anova_svm.predict(X)\n",
       ">>> anova_svm.score(X, y)                        # doctest: +ELLIPSIS\n",
       "0.83\n",
       ">>> # getting the selected features chosen by anova_filter\n",
       ">>> anova_svm.named_steps['anova'].get_support()\n",
       "... # doctest: +NORMALIZE_WHITESPACE\n",
       "array([False, False,  True,  True, False, False, True,  True, False,\n",
       "       True,  False,  True,  True, False, True,  False, True, True,\n",
       "       False, False])\n",
       ">>> # Another way to get selected features chosen by anova_filter\n",
       ">>> anova_svm.named_steps.anova.get_support()\n",
       "... # doctest: +NORMALIZE_WHITESPACE\n",
       "array([False, False,  True,  True, False, False, True,  True, False,\n",
       "       True,  False,  True,  True, False, True,  False, True, True,\n",
       "       False, False])\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True, False, False,  True,  True, False,\n",
       "        True, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = [\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"polinomial\", PolynomialFeatures(degree=2)),\n",
    "    (\"model\", LinearRegression())\n",
    "]\n",
    "\n",
    "pipe = Pipeline(input)\n",
    "# (X[\"horsepower\", \"curb-weight\", \"engine-size\", \"highway-mpg\"], y)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# generate some data to play with\n",
    "X, y = samples_generator.make_classification(n_informative=5, n_redundant=0, random_state=42)\n",
    "X, y\n",
    "\n",
    "# initialize a SelectKBest object, this selects top 5 features\n",
    "anova_filter = SelectKBest(f_regression, k=5)\n",
    "\n",
    "# initialize a C-Support Veector Classification\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# put them in a pipeline\n",
    "anova_svm = Pipeline([\n",
    "    ('anova', anova_filter), \n",
    "    ('svc', clf)])\n",
    "\n",
    "# set parameters of the pipeline\n",
    "# params use \"__\" beetween the name of the element in the pipeline and the name of the parameter\n",
    "anova_svm.set_params(anova__k=10, svc__C=.1).fit(X, y)\n",
    "\n",
    "# generate the prediction using the pipeline\n",
    "prediction = anova_svm.predict(X)\n",
    "\n",
    "# show anova test R^2 score\n",
    "anova_svm.score(X, y)\n",
    "\n",
    "# getting the selected features chosen by anova_filter\n",
    "# accesing one of the steps\n",
    "anova_svm.named_steps['anova'].get_support()\n",
    "\n",
    "\n",
    "# ?samples_generator.make_classification\n",
    "# ?SelectKBest\n",
    "# ?svm.SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## measures for in-sample evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmultioutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform_average'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Mean squared error regression loss\n",
       "\n",
       "Read more in the :ref:`User Guide <mean_squared_error>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
       "    Ground truth (correct) target values.\n",
       "\n",
       "y_pred : array-like of shape = (n_samples) or (n_samples, n_outputs)\n",
       "    Estimated target values.\n",
       "\n",
       "sample_weight : array-like of shape = (n_samples), optional\n",
       "    Sample weights.\n",
       "\n",
       "multioutput : string in ['raw_values', 'uniform_average']\n",
       "    or array-like of shape (n_outputs)\n",
       "    Defines aggregating of multiple output values.\n",
       "    Array-like value defines weights used to average errors.\n",
       "\n",
       "    'raw_values' :\n",
       "        Returns a full set of errors in case of multioutput input.\n",
       "\n",
       "    'uniform_average' :\n",
       "        Errors of all outputs are averaged with uniform weight.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "loss : float or ndarray of floats\n",
       "    A non-negative floating point value (the best value is 0.0), or an\n",
       "    array of floating point values, one for each individual target.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import mean_squared_error\n",
       ">>> y_true = [3, -0.5, 2, 7]\n",
       ">>> y_pred = [2.5, 0.0, 2, 8]\n",
       ">>> mean_squared_error(y_true, y_pred)\n",
       "0.375\n",
       ">>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
       ">>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
       ">>> mean_squared_error(y_true, y_pred)  # doctest: +ELLIPSIS\n",
       "0.708...\n",
       ">>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
       "... # doctest: +ELLIPSIS\n",
       "array([0.41666667, 1.        ])\n",
       ">>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
       "... # doctest: +ELLIPSIS\n",
       "0.825...\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/sklearn/metrics/regression.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Gives a new shape to an array without changing its data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : array_like\n",
       "    Array to be reshaped.\n",
       "newshape : int or tuple of ints\n",
       "    The new shape should be compatible with the original shape. If\n",
       "    an integer, then the result will be a 1-D array of that length.\n",
       "    One shape dimension can be -1. In this case, the value is\n",
       "    inferred from the length of the array and remaining dimensions.\n",
       "order : {'C', 'F', 'A'}, optional\n",
       "    Read the elements of `a` using this index order, and place the\n",
       "    elements into the reshaped array using this index order.  'C'\n",
       "    means to read / write the elements using C-like index order,\n",
       "    with the last axis index changing fastest, back to the first\n",
       "    axis index changing slowest. 'F' means to read / write the\n",
       "    elements using Fortran-like index order, with the first index\n",
       "    changing fastest, and the last index changing slowest. Note that\n",
       "    the 'C' and 'F' options take no account of the memory layout of\n",
       "    the underlying array, and only refer to the order of indexing.\n",
       "    'A' means to read / write the elements in Fortran-like index\n",
       "    order if `a` is Fortran *contiguous* in memory, C-like order\n",
       "    otherwise.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "reshaped_array : ndarray\n",
       "    This will be a new view object if possible; otherwise, it will\n",
       "    be a copy.  Note there is no guarantee of the *memory layout* (C- or\n",
       "    Fortran- contiguous) of the returned array.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ndarray.reshape : Equivalent method.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "It is not always possible to change the shape of an array without\n",
       "copying the data. If you want an error to be raised when the data is copied,\n",
       "you should assign the new shape to the shape attribute of the array::\n",
       "\n",
       " >>> a = np.zeros((10, 2))\n",
       " # A transpose makes the array non-contiguous\n",
       " >>> b = a.T\n",
       " # Taking a view makes it possible to modify the shape without modifying\n",
       " # the initial object.\n",
       " >>> c = b.view()\n",
       " >>> c.shape = (20)\n",
       " AttributeError: incompatible shape for a non-contiguous array\n",
       "\n",
       "The `order` keyword gives the index ordering both for *fetching* the values\n",
       "from `a`, and then *placing* the values into the output array.\n",
       "For example, let's say you have an array:\n",
       "\n",
       ">>> a = np.arange(6).reshape((3, 2))\n",
       ">>> a\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])\n",
       "\n",
       "You can think of reshaping as first raveling the array (using the given\n",
       "index order), then inserting the elements from the raveled array into the\n",
       "new array using the same kind of index ordering as was used for the\n",
       "raveling.\n",
       "\n",
       ">>> np.reshape(a, (2, 3)) # C-like index ordering\n",
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])\n",
       ">>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n",
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])\n",
       ">>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering\n",
       "array([[0, 4, 3],\n",
       "       [2, 1, 5]])\n",
       ">>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')\n",
       "array([[0, 4, 3],\n",
       "       [2, 1, 5]])\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.array([[1,2,3], [4,5,6]])\n",
       ">>> np.reshape(a, 6)\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       ">>> np.reshape(a, 6, order='F')\n",
       "array([1, 4, 2, 5, 3, 6])\n",
       "\n",
       ">>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# generating some input data\n",
    "some_input = np.arange(1,101,1).reshape(-1,1)\n",
    "# some_input\n",
    "?np.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-on-jupyter@2.0.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
